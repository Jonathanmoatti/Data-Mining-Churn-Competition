{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:55:22.287168Z",
     "start_time": "2020-01-08T14:55:18.643386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmonn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\mmonn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\mmonn\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load, dump\n",
    "from sas7bdat import SAS7BDAT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,roc_curve, roc_auc_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence,plot_objective, plot_evaluations\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:55:22.450619Z",
     "start_time": "2020-01-08T14:55:22.289149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Smaller helped function for visualization\n",
    "def display_all(df):\n",
    "    '''\n",
    "    Small helper function to allow us to disaply 1000 rows and columns. This will come in handy \n",
    "    because we are dealing with a lot of columns\n",
    "    '''\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:55:57.959206Z",
     "start_time": "2020-01-08T14:55:47.938093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "df = pd.read_sas('churn.sas7bdat', format='sas7bdat', encoding='iso-8859-1')\n",
    "df_test = pd.read_sas('churn_test.sas7bdat', format='sas7bdat', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:55:58.124566Z",
     "start_time": "2020-01-08T14:55:57.959206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.churn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:56:04.668559Z",
     "start_time": "2020-01-08T14:56:04.467841Z"
    }
   },
   "outputs": [],
   "source": [
    "df.churn = df.churn.astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debut Cleaning (Fastai Method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:56:25.496097Z",
     "start_time": "2020-01-08T14:56:15.441436Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_sas('churn.sas7bdat', format='sas7bdat', encoding='iso-8859-1')\n",
    "df_test1 = pd.read_sas('churn_test.sas7bdat', format='sas7bdat', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:24.179007Z",
     "start_time": "2020-01-06T03:49:21.996844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmonn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#ATTENTION VARIABLES IMPORTANTES A MODIFIER AVANT TRAITEMENT\n",
    "#mailflag NAN a \"Y\" car dans documentation NaN signifie que cette personne est ouverte a recevoir des mails promotionnels\n",
    "#Retdays NAN a 9999, nombre de jours depuis dernier appel, si NaN alors cette personne n'a jamais ete contacter donc mettre haute valeur\n",
    "#solflag NAN a \"Y\". Meme chose que pour mailflag.\n",
    "\n",
    "def trans(X):\n",
    "    X.mailflag.fillna(value = 'Y',inplace = True)\n",
    "    #recoder les nan de retdays a 999 (tps depuis dernier appel de retention, max 984 ds base donnees)\n",
    "    X.retdays[X['retdays'].isnull()] = 9999\n",
    "    #convertir les nan en Y\n",
    "    X.solflag.fillna(value = 'Y',inplace = True)\n",
    "    \n",
    "trans(df1)\n",
    "trans(df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:24.796386Z",
     "start_time": "2020-01-06T03:49:24.181008Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.churn = df.churn.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:26.270442Z",
     "start_time": "2020-01-06T03:49:24.798349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical variables that are not type cat or object in original dataset. Must be transformed.\n",
    "cats_cap = ['TRUCK',  'WRKWOMAN', 'SOLFLAG', 'RV', 'REFURB_NEW', 'PROPTYPE', \n",
    "'MTRCYCLE', 'INCOME', 'FORGNTVL', 'EDUC1', 'CRTCOUNT', 'ADULTS', 'LOR', 'MODELS', \n",
    "            'PHONES', 'UNIQSUBS',  'TOT_RET', 'TOT_ACPT', 'MONTHS']\n",
    "cats = []\n",
    "for i in cats_cap:\n",
    "    cats.append(i.lower())\n",
    "\n",
    "for i in cats:\n",
    "    df1[i] = df1[i].astype('category')\n",
    "    df_test1[i] = df_test1[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:26.876836Z",
     "start_time": "2020-01-06T03:49:26.272443Z"
    }
   },
   "outputs": [],
   "source": [
    "cat = []\n",
    "cont = []\n",
    "y = 'churn'\n",
    "for n,c in df1.items():\n",
    "    if n == 'churn' or n in cats:\n",
    "        continue\n",
    "    if is_string_dtype(c): cat.append(n) \n",
    "    else: cont.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:27.492319Z",
     "start_time": "2020-01-06T03:49:26.877831Z"
    }
   },
   "outputs": [],
   "source": [
    "#Transform all training data categorical variables to category type.\n",
    "#VERY IMPORTANT : Must be used on TRAINING set to define the mapping (ici on FIT)\n",
    "def train_cats(df):\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "            \n",
    "#VERY IMPORTANT : Must be used on TEST set to apply the mapping from train_cats (ici we TRANSFORM)          \n",
    "def apply_cats(df):\n",
    "    for n,c in df.items():\n",
    "        if (n in df1.columns) and (df1[n].dtype.name=='category'):\n",
    "            df[n] = c.astype('category').cat.as_ordered() # same code as train_cats(df1)\n",
    "            df[n].cat.set_categories(df1[n].cat.categories, ordered=True, inplace=True) # Use df1 as a template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:28.659062Z",
     "start_time": "2020-01-06T03:49:27.494152Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply functions from the previous cell on our train and test dataset respectively.\n",
    "train_cats(df1)\n",
    "apply_cats(df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:29.254463Z",
     "start_time": "2020-01-06T03:49:28.661042Z"
    }
   },
   "outputs": [],
   "source": [
    "#The two following functions, numericalize and fix_missing are only created to be used in the main function, df_proc.\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    '''\n",
    "    Details: If the column is not numeric, AND if max_n_cat is not specified OR if the number of categories \n",
    "             in the columns is <= max_n_cat, then we replace the column by its category codes\n",
    "    '''\n",
    "    if not is_numeric_dtype(col) and (max_n_cat is None or len(col.cat.categories)>max_n_cat):\n",
    "        df[name] = pd.Categorical(col).codes+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:29.860986Z",
     "start_time": "2020-01-06T03:49:29.256424Z"
    }
   },
   "outputs": [],
   "source": [
    "#We fill NA's with the median value. For this work i have tried many different type of imputation (KNN, MICE, Mode, Median, Average)\n",
    "#Best results were obtained with the median (surprising) so thats what i used as imputation method.\n",
    "def fix_missing(df, col, name, na_dict):\n",
    "    '''\n",
    "    Details: If the column has null values or if we passed in a na_dict:\n",
    "             Then we create a new column [name+'_na'] indicating where the NaNs were\n",
    "             \n",
    "    '''\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:30.502090Z",
     "start_time": "2020-01-06T03:49:29.862801Z"
    }
   },
   "outputs": [],
   "source": [
    "def proc_df(df, y_fld=None, na_dict=None, max_n_cat=None):   \n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    if y_fld is None:\n",
    "        y = None\n",
    "        y_fld = []\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = pd.Categorical(df[y_fld]).codes\n",
    "        y = df[y_fld].values\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    else: na_dict = na_dict.copy()\n",
    "    na_dict_initial = na_dict.copy()\n",
    "    \n",
    "    # Call fix_missing() to replace NaN values by the median, and create new NaN columns\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if len(na_dict_initial.keys()) > 0:\n",
    "        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n",
    "        \n",
    "    # Apply numericalize() to change a column to it's category code\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    df = pd.get_dummies(df, dummy_na=True) # get_dummie checks for everything that is still a category and OneHotEncodes\n",
    "    \n",
    "    res = [df, y, na_dict]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:31.486644Z",
     "start_time": "2020-01-06T03:49:30.504085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply proc_df to transform our dataframe, remove NAs and create new columns with NAs (FIT --> FOR TRAIN SET)\n",
    "df1, y, nas = proc_df(df1, 'churn', max_n_cat=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:32.453060Z",
     "start_time": "2020-01-06T03:49:31.487640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply proc_df to the test dataframe (TRANSFORM --> PASS IN TEST SET TO APPLY THE TRAIN SET MAPPING. TRES IMPORTANT)\n",
    "df_test1, _, nas = proc_df(df_test1, na_dict=nas, max_n_cat=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:49:33.069410Z",
     "start_time": "2020-01-06T03:49:32.454057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 314), (50000, 313))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape, df_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T03:13:09.364914Z",
     "start_time": "2020-01-06T03:13:08.670627Z"
    }
   },
   "outputs": [],
   "source": [
    "#save as Pickle. Faster to load afterwards.\n",
    "df1.to_pickle('train_final.pkl')\n",
    "df_test1.to_pickle('test_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:08:28.459826Z",
     "start_time": "2020-01-08T15:08:28.193851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 314)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set\n",
    "df = pd.read_pickle('train_final.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:08:30.675967Z",
     "start_time": "2020-01-08T15:08:30.426730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 313)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set\n",
    "df_final = pd.read_pickle('test_final.pkl')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:08:31.543199Z",
     "start_time": "2020-01-08T15:08:31.365061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>rev_Range</th>\n",
       "      <th>...</th>\n",
       "      <th>car_buy_New</th>\n",
       "      <th>car_buy_UNKNOWN</th>\n",
       "      <th>car_buy_nan</th>\n",
       "      <th>adults_1.0</th>\n",
       "      <th>adults_2.0</th>\n",
       "      <th>adults_3.0</th>\n",
       "      <th>adults_4.0</th>\n",
       "      <th>adults_5.0</th>\n",
       "      <th>adults_6.0</th>\n",
       "      <th>adults_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.4925</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.425</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9900</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.2300</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.2750</td>\n",
       "      <td>1312.25</td>\n",
       "      <td>75.000</td>\n",
       "      <td>1.2375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.42</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.1450</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean  da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0   57.4925    482.75       37.425   0.2475        22.75          9.1   \n",
       "1   16.9900     10.25       16.990   0.0000         0.00          0.0   \n",
       "2   55.2300    570.50       71.980   0.0000         0.00          0.0   \n",
       "3   82.2750   1312.25       75.000   1.2375         0.00          0.0   \n",
       "4   17.1450      0.00       16.990   0.0000         0.00          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  rev_Range  ...  car_buy_New  \\\n",
       "0          9.1          0.0        0.0     153.14  ...            0   \n",
       "1          0.0          0.0        0.0       0.00  ...            1   \n",
       "2          0.0          0.0        0.0       0.00  ...            1   \n",
       "3          0.0          0.0        0.0      15.42  ...            1   \n",
       "4          0.0          0.0        0.0       0.31  ...            0   \n",
       "\n",
       "   car_buy_UNKNOWN  car_buy_nan  adults_1.0  adults_2.0  adults_3.0  \\\n",
       "0                1            0           1           0           0   \n",
       "1                0            0           0           1           0   \n",
       "2                0            0           1           0           0   \n",
       "3                0            0           1           0           0   \n",
       "4                1            0           0           0           1   \n",
       "\n",
       "   adults_4.0  adults_5.0  adults_6.0  adults_nan  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debut creation modele : XGBoost with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:15:11.161922Z",
     "start_time": "2020-01-08T15:15:10.956782Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('churn',axis=1)\n",
    "y = df.churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation / Test. 60% train, 20% validation, 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:15:12.224427Z",
     "start_time": "2020-01-08T15:15:11.953769Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test_val,y_train,y_test_val = train_test_split(X,y,test_size=0.4,random_state=657)\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_test_val,y_test_val,test_size=0.5,random_state=657)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation wrapper function pour SKopt\n",
    "Using this wrapper to be able to follow each iterations hyperparameter values and accuracy, in case computer crashs or power shortage, get to keep the results of all on-going iterations, and most importantly the best hyper-parameters obtained before crash / shortage / ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:15:13.365466Z",
     "start_time": "2020-01-08T15:15:13.174701Z"
    }
   },
   "outputs": [],
   "source": [
    "def result(func):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        res = func(*args,**kwargs)\n",
    "        print(*args,**kwargs)\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:15:34.839371Z",
     "start_time": "2020-01-08T15:15:34.662270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters \n",
    "\n",
    "learning_rate = Real(low=0.001, high=0.2, prior='uniform', name='learning_rate')\n",
    "gamma = Real(low = 0, high = 0.02, prior='uniform', name='gamma')\n",
    "n_estimators = Integer(low=50, high = 4000,name='n_estimators')\n",
    "max_depth = Integer(low=1, high=12, name='max_depth')\n",
    "subsample = Real(low = 0.3, high=1,name='subsample')\n",
    "colsample_bytree = Real(low=0.3, high=1, name='colsample_bytree')\n",
    "reg_alpha = Real(low=0, high=15,name='reg_alpha')\n",
    "reg_lambda = Real(low=0, high=15,name='reg_lambda')\n",
    "booster = Categorical(('gbtree', 'gblinear', 'dart'), name = 'booster')             \n",
    "dimensions = [learning_rate, gamma,n_estimators,max_depth,subsample,colsample_bytree,reg_alpha, reg_lambda,booster]\n",
    "\n",
    "nb_calls = 11\n",
    "\n",
    "default_parameters = [0.02097570461116089, 0.0012850274242561758, 3779, 3, 0.7143115552529244, 0.9652482625436429, 5.501545045646806, 0.32428041642913136,'gbtree'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation wrapper as decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:15:40.755049Z",
     "start_time": "2020-01-08T15:15:40.585363Z"
    }
   },
   "outputs": [],
   "source": [
    "@result\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate,gamma,n_estimators,max_depth,subsample,colsample_bytree,reg_alpha,reg_lambda,booster):\n",
    "    xg_opt = XGBClassifier(learning_rate=learning_rate,\n",
    "                               gamma=gamma,\n",
    "                               n_estimators=n_estimators,\n",
    "                               max_depth=max_depth,\n",
    "                               subsample=subsample,\n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               reg_alpha=reg_alpha,\n",
    "                               reg_lambda=reg_lambda,\n",
    "                               n_jobs=-1,\n",
    "                               booster=booster,\n",
    "                            verbose=True)\n",
    "    xg_opt.fit(X_train, y_train)\n",
    "    accurracy = xg_opt.score(X_val, y_val)\n",
    "    return -accurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:56:14.713992Z",
     "start_time": "2020-01-08T15:15:41.163559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at provided point.\n",
      "[0.02097570461116089, 0.0012850274242561758, 3779, 3, 0.7143115552529244, 0.9652482625436429, 5.501545045646806, 0.32428041642913136, 'gbtree']\n",
      "Iteration No: 1 ended. Evaluation done at provided point.\n",
      "Time taken: 308.8332\n",
      "Function value obtained: -0.6494\n",
      "Current minimum: -0.6494\n",
      "Iteration No: 2 started. Evaluating function at random point.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a57b14f25dac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                random_state=4)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-9ccc9c5bf8f7>\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-2ec397aa61da>\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(learning_rate, gamma, n_estimators, max_depth, subsample, colsample_bytree, reg_alpha, reg_lambda, booster)\u001b[0m\n\u001b[0;32m     13\u001b[0m                                \u001b[0mbooster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                             verbose=True)\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mxg_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0maccurracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxg_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0maccurracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    search_result = gp_minimize(func=fitness,\n",
    "                               dimensions=dimensions,\n",
    "                               acq_func='EI',\n",
    "                               n_calls=nb_calls,\n",
    "                               x0=default_parameters,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=True,\n",
    "                               random_state=4)\n",
    "    \n",
    "print(search_result.x)\n",
    "print(search_result.fun)\n",
    "plot = plot_convergence(search_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the results of XGBoost Skopt and creating graphs of the distribution of parameters estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T21:41:06.518921Z",
     "start_time": "2019-11-28T21:41:06.514929Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions1 = ['learning_rate', 'gamma', 'n_estimators', 'max_depth', 'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T21:41:07.634774Z",
     "start_time": "2019-11-28T21:41:07.618814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>3779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714312</td>\n",
       "      <td>0.965248</td>\n",
       "      <td>5.501545</td>\n",
       "      <td>0.324280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>3430</td>\n",
       "      <td>8</td>\n",
       "      <td>0.718289</td>\n",
       "      <td>0.399025</td>\n",
       "      <td>3.367589</td>\n",
       "      <td>10.476304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180733</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>0.553047</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>5.876493</td>\n",
       "      <td>12.179216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122893</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>2593</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313317</td>\n",
       "      <td>0.327846</td>\n",
       "      <td>14.175058</td>\n",
       "      <td>6.695238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088828</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>745</td>\n",
       "      <td>11</td>\n",
       "      <td>0.890470</td>\n",
       "      <td>0.947607</td>\n",
       "      <td>13.054597</td>\n",
       "      <td>12.528851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate     gamma  n_estimators  max_depth  subsample  \\\n",
       "0       0.020976  0.001285          3779          3   0.714312   \n",
       "1       0.180224  0.003454          3430          8   0.718289   \n",
       "2       0.180733  0.012659            70          7   0.553047   \n",
       "3       0.122893  0.005329          2593         10   0.313317   \n",
       "4       0.088828  0.001314           745         11   0.890470   \n",
       "\n",
       "   colsample_bytree  reg_alpha  reg_lambda  \n",
       "0          0.965248   5.501545    0.324280  \n",
       "1          0.399025   3.367589   10.476304  \n",
       "2          0.722892   5.876493   12.179216  \n",
       "3          0.327846  14.175058    6.695238  \n",
       "4          0.947607  13.054597   12.528851  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create dataframe of columns with feature iterations\n",
    "loc_iter = pd.DataFrame(search_result.x_iters, columns=dimensions1)\n",
    "display(loc_iter.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.64370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.62135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.63120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.61515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.63230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0 -0.64370\n",
       "1 -0.62135\n",
       "2 -0.63120\n",
       "3 -0.61515\n",
       "4 -0.63230"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe with accuracy iterations\n",
    "xgb_results = pd.DataFrame(search_result['func_vals'])\n",
    "xgb_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T21:58:00.713233Z",
     "start_time": "2019-11-28T21:58:00.692281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_iter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>3779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714312</td>\n",
       "      <td>0.965248</td>\n",
       "      <td>5.501545</td>\n",
       "      <td>0.324280</td>\n",
       "      <td>-0.64370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>3430</td>\n",
       "      <td>8</td>\n",
       "      <td>0.718289</td>\n",
       "      <td>0.399025</td>\n",
       "      <td>3.367589</td>\n",
       "      <td>10.476304</td>\n",
       "      <td>-0.62135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180733</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>0.553047</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>5.876493</td>\n",
       "      <td>12.179216</td>\n",
       "      <td>-0.63120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122893</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>2593</td>\n",
       "      <td>10</td>\n",
       "      <td>0.313317</td>\n",
       "      <td>0.327846</td>\n",
       "      <td>14.175058</td>\n",
       "      <td>6.695238</td>\n",
       "      <td>-0.61515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088828</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>745</td>\n",
       "      <td>11</td>\n",
       "      <td>0.890470</td>\n",
       "      <td>0.947607</td>\n",
       "      <td>13.054597</td>\n",
       "      <td>12.528851</td>\n",
       "      <td>-0.63230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.061961</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>562</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>3.891410</td>\n",
       "      <td>14.758651</td>\n",
       "      <td>-0.64155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.178815</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>3904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985207</td>\n",
       "      <td>0.597997</td>\n",
       "      <td>14.253616</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>-0.63215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.088617</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>0.983026</td>\n",
       "      <td>0.895058</td>\n",
       "      <td>14.720245</td>\n",
       "      <td>7.917668</td>\n",
       "      <td>-0.63725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.103486</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>2092</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958981</td>\n",
       "      <td>0.989001</td>\n",
       "      <td>13.654126</td>\n",
       "      <td>14.521822</td>\n",
       "      <td>-0.63805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>764</td>\n",
       "      <td>12</td>\n",
       "      <td>0.318037</td>\n",
       "      <td>0.887279</td>\n",
       "      <td>3.224875</td>\n",
       "      <td>0.842832</td>\n",
       "      <td>-0.63140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         learning_rate     gamma  n_estimators  max_depth  subsample  \\\n",
       "nb_iter                                                                \n",
       "0             0.020976  0.001285          3779          3   0.714312   \n",
       "1             0.180224  0.003454          3430          8   0.718289   \n",
       "2             0.180733  0.012659            70          7   0.553047   \n",
       "3             0.122893  0.005329          2593         10   0.313317   \n",
       "4             0.088828  0.001314           745         11   0.890470   \n",
       "...                ...       ...           ...        ...        ...   \n",
       "295           0.061961  0.018067           562          4   0.993882   \n",
       "296           0.178815  0.019218          3904          2   0.985207   \n",
       "297           0.088617  0.012824            66          6   0.983026   \n",
       "298           0.103486  0.009468          2092          3   0.958981   \n",
       "299           0.026790  0.002786           764         12   0.318037   \n",
       "\n",
       "         colsample_bytree  reg_alpha  reg_lambda  accuracy  \n",
       "nb_iter                                                     \n",
       "0                0.965248   5.501545    0.324280  -0.64370  \n",
       "1                0.399025   3.367589   10.476304  -0.62135  \n",
       "2                0.722892   5.876493   12.179216  -0.63120  \n",
       "3                0.327846  14.175058    6.695238  -0.61515  \n",
       "4                0.947607  13.054597   12.528851  -0.63230  \n",
       "...                   ...        ...         ...       ...  \n",
       "295              0.846953   3.891410   14.758651  -0.64155  \n",
       "296              0.597997  14.253616    0.676545  -0.63215  \n",
       "297              0.895058  14.720245    7.917668  -0.63725  \n",
       "298              0.989001  13.654126   14.521822  -0.63805  \n",
       "299              0.887279   3.224875    0.842832  -0.63140  \n",
       "\n",
       "[300 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#concat feature iteration with accuracy iteration\n",
    "loc_iter = pd.concat([loc_iter, xgb_results], axis=1)\n",
    "loc_iter.rename(columns={0:'accuracy'}, inplace=True)\n",
    "loc_iter.index.name='nb_iter'\n",
    "display(loc_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T21:59:21.948687Z",
     "start_time": "2019-11-28T21:59:21.927777Z"
    }
   },
   "outputs": [],
   "source": [
    "#sorting the values by accuracy\n",
    "loc_iter.sort_values(by='accuracy', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_iter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>3663</td>\n",
       "      <td>5</td>\n",
       "      <td>0.329935</td>\n",
       "      <td>0.776129</td>\n",
       "      <td>3.291162</td>\n",
       "      <td>4.655269</td>\n",
       "      <td>-0.64475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>1279</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992360</td>\n",
       "      <td>0.605307</td>\n",
       "      <td>14.777950</td>\n",
       "      <td>0.783418</td>\n",
       "      <td>-0.64460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.066429</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.582868</td>\n",
       "      <td>13.231439</td>\n",
       "      <td>12.994221</td>\n",
       "      <td>-0.64445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>3462</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987440</td>\n",
       "      <td>0.585410</td>\n",
       "      <td>13.731212</td>\n",
       "      <td>11.457777</td>\n",
       "      <td>-0.64430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>3779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714312</td>\n",
       "      <td>0.965248</td>\n",
       "      <td>5.501545</td>\n",
       "      <td>0.324280</td>\n",
       "      <td>-0.64370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>3779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714312</td>\n",
       "      <td>0.965248</td>\n",
       "      <td>5.501545</td>\n",
       "      <td>0.324280</td>\n",
       "      <td>-0.64370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.039777</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>2599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>9.340881</td>\n",
       "      <td>14.972215</td>\n",
       "      <td>-0.64360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>870</td>\n",
       "      <td>8</td>\n",
       "      <td>0.986324</td>\n",
       "      <td>0.461517</td>\n",
       "      <td>14.462334</td>\n",
       "      <td>0.403054</td>\n",
       "      <td>-0.64355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>1041</td>\n",
       "      <td>9</td>\n",
       "      <td>0.953782</td>\n",
       "      <td>0.950813</td>\n",
       "      <td>13.174125</td>\n",
       "      <td>4.189244</td>\n",
       "      <td>-0.64350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.067828</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2477</td>\n",
       "      <td>2</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.64335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>0.966017</td>\n",
       "      <td>13.130732</td>\n",
       "      <td>12.597376</td>\n",
       "      <td>-0.64325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>3397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.406996</td>\n",
       "      <td>13.357600</td>\n",
       "      <td>12.587838</td>\n",
       "      <td>-0.64300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>2860</td>\n",
       "      <td>6</td>\n",
       "      <td>0.967725</td>\n",
       "      <td>0.973763</td>\n",
       "      <td>13.966937</td>\n",
       "      <td>0.394683</td>\n",
       "      <td>-0.64290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>3259</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956237</td>\n",
       "      <td>0.444594</td>\n",
       "      <td>0.334067</td>\n",
       "      <td>0.248236</td>\n",
       "      <td>-0.64280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.027346</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>2943</td>\n",
       "      <td>4</td>\n",
       "      <td>0.956942</td>\n",
       "      <td>0.622532</td>\n",
       "      <td>13.967866</td>\n",
       "      <td>14.858967</td>\n",
       "      <td>-0.64275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>2337</td>\n",
       "      <td>10</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.928386</td>\n",
       "      <td>5.548046</td>\n",
       "      <td>0.741954</td>\n",
       "      <td>-0.64260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3938</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.64230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>1810</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993180</td>\n",
       "      <td>0.834541</td>\n",
       "      <td>13.642555</td>\n",
       "      <td>6.452153</td>\n",
       "      <td>-0.64230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>3285</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990177</td>\n",
       "      <td>0.976091</td>\n",
       "      <td>1.731702</td>\n",
       "      <td>13.896799</td>\n",
       "      <td>-0.64230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>3346</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876414</td>\n",
       "      <td>0.399424</td>\n",
       "      <td>14.697309</td>\n",
       "      <td>14.267572</td>\n",
       "      <td>-0.64230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.048317</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>789</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.992814</td>\n",
       "      <td>8.909305</td>\n",
       "      <td>9.403998</td>\n",
       "      <td>-0.64220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>1425</td>\n",
       "      <td>8</td>\n",
       "      <td>0.990634</td>\n",
       "      <td>0.937871</td>\n",
       "      <td>13.650221</td>\n",
       "      <td>12.299975</td>\n",
       "      <td>-0.64210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.054613</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>1425</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.970334</td>\n",
       "      <td>3.219327</td>\n",
       "      <td>14.346987</td>\n",
       "      <td>-0.64210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>3305</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984438</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>12.893570</td>\n",
       "      <td>1.712523</td>\n",
       "      <td>-0.64205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.049109</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>1958</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>0.593668</td>\n",
       "      <td>11.800530</td>\n",
       "      <td>12.621982</td>\n",
       "      <td>-0.64200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>3936</td>\n",
       "      <td>8</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.673556</td>\n",
       "      <td>14.704642</td>\n",
       "      <td>5.176146</td>\n",
       "      <td>-0.64195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>1043</td>\n",
       "      <td>3</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.982363</td>\n",
       "      <td>14.296963</td>\n",
       "      <td>14.103147</td>\n",
       "      <td>-0.64190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>279</td>\n",
       "      <td>12</td>\n",
       "      <td>0.955708</td>\n",
       "      <td>0.907606</td>\n",
       "      <td>13.606182</td>\n",
       "      <td>0.777670</td>\n",
       "      <td>-0.64185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>3995</td>\n",
       "      <td>10</td>\n",
       "      <td>0.932150</td>\n",
       "      <td>0.539095</td>\n",
       "      <td>7.873562</td>\n",
       "      <td>9.436934</td>\n",
       "      <td>-0.64185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.066141</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>1735</td>\n",
       "      <td>2</td>\n",
       "      <td>0.694564</td>\n",
       "      <td>0.841257</td>\n",
       "      <td>8.524519</td>\n",
       "      <td>13.551454</td>\n",
       "      <td>-0.64175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>759</td>\n",
       "      <td>8</td>\n",
       "      <td>0.954017</td>\n",
       "      <td>0.955435</td>\n",
       "      <td>0.617934</td>\n",
       "      <td>12.667184</td>\n",
       "      <td>-0.64175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>2288</td>\n",
       "      <td>6</td>\n",
       "      <td>0.981625</td>\n",
       "      <td>0.363602</td>\n",
       "      <td>12.590141</td>\n",
       "      <td>11.774385</td>\n",
       "      <td>-0.64175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>2572</td>\n",
       "      <td>12</td>\n",
       "      <td>0.992555</td>\n",
       "      <td>0.823604</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>7.446417</td>\n",
       "      <td>-0.64170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.061317</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>2874</td>\n",
       "      <td>2</td>\n",
       "      <td>0.650587</td>\n",
       "      <td>0.303231</td>\n",
       "      <td>6.538552</td>\n",
       "      <td>9.283926</td>\n",
       "      <td>-0.64170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.061961</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>562</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>3.891410</td>\n",
       "      <td>14.758651</td>\n",
       "      <td>-0.64155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>3140</td>\n",
       "      <td>9</td>\n",
       "      <td>0.960914</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>14.819613</td>\n",
       "      <td>5.590046</td>\n",
       "      <td>-0.64150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.048560</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>3997</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991978</td>\n",
       "      <td>0.830616</td>\n",
       "      <td>11.728140</td>\n",
       "      <td>8.522373</td>\n",
       "      <td>-0.64150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>3172</td>\n",
       "      <td>12</td>\n",
       "      <td>0.482019</td>\n",
       "      <td>0.478189</td>\n",
       "      <td>10.538324</td>\n",
       "      <td>1.723968</td>\n",
       "      <td>-0.64145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>3359</td>\n",
       "      <td>11</td>\n",
       "      <td>0.801929</td>\n",
       "      <td>0.928958</td>\n",
       "      <td>12.326271</td>\n",
       "      <td>12.820286</td>\n",
       "      <td>-0.64135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.062284</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>1686</td>\n",
       "      <td>3</td>\n",
       "      <td>0.991212</td>\n",
       "      <td>0.991926</td>\n",
       "      <td>14.616288</td>\n",
       "      <td>14.718388</td>\n",
       "      <td>-0.64120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         learning_rate     gamma  n_estimators  max_depth  subsample  \\\n",
       "nb_iter                                                                \n",
       "102           0.003659  0.006509          3663          5   0.329935   \n",
       "272           0.043577  0.017540          1279          4   0.992360   \n",
       "270           0.066429  0.002667           593          4   0.968295   \n",
       "261           0.061382  0.000234          3462          2   0.987440   \n",
       "0             0.020976  0.001285          3779          3   0.714312   \n",
       "10            0.020976  0.001285          3779          3   0.714312   \n",
       "282           0.039777  0.000970          2599          3   0.932857   \n",
       "255           0.018223  0.001583           870          8   0.986324   \n",
       "211           0.005322  0.012503          1041          9   0.953782   \n",
       "67            0.067828  0.020000          2477          2   0.612218   \n",
       "252           0.080776  0.003512           910          3   0.999178   \n",
       "149           0.032857  0.015581          3397          3   0.998684   \n",
       "125           0.006317  0.017249          2860          6   0.967725   \n",
       "200           0.002266  0.018211          3259         10   0.956237   \n",
       "283           0.027346  0.001992          2943          4   0.956942   \n",
       "190           0.004260  0.017759          2337         10   0.985890   \n",
       "43            0.001000  0.000000          3938         12   0.300000   \n",
       "189           0.076390  0.001352          1810          2   0.993180   \n",
       "158           0.011210  0.001361          3285          5   0.990177   \n",
       "180           0.021564  0.002179          3346          4   0.876414   \n",
       "147           0.048317  0.001465           789          5   0.978740   \n",
       "164           0.009279  0.014003          1425          8   0.990634   \n",
       "176           0.054613  0.016242          1425          3   0.982000   \n",
       "202           0.047256  0.019188          3305          2   0.984438   \n",
       "285           0.049109  0.000550          1958          3   0.999215   \n",
       "260           0.003039  0.001574          3936          8   0.959459   \n",
       "212           0.058942  0.011777          1043          3   0.928696   \n",
       "87            0.018659  0.000258           279         12   0.955708   \n",
       "91            0.002874  0.002286          3995         10   0.932150   \n",
       "113           0.066141  0.003618          1735          2   0.694564   \n",
       "219           0.029429  0.019015           759          8   0.954017   \n",
       "242           0.021198  0.015676          2288          6   0.981625   \n",
       "206           0.005998  0.017993          2572         12   0.992555   \n",
       "101           0.061317  0.002661          2874          2   0.650587   \n",
       "295           0.061961  0.018067           562          4   0.993882   \n",
       "121           0.001570  0.019228          3140          9   0.960914   \n",
       "188           0.048560  0.018777          3997          2   0.991978   \n",
       "119           0.001652  0.018312          3172         12   0.482019   \n",
       "129           0.001542  0.009897          3359         11   0.801929   \n",
       "247           0.062284  0.015896          1686          3   0.991212   \n",
       "\n",
       "         colsample_bytree  reg_alpha  reg_lambda  accuracy  \n",
       "nb_iter                                                     \n",
       "102              0.776129   3.291162    4.655269  -0.64475  \n",
       "272              0.605307  14.777950    0.783418  -0.64460  \n",
       "270              0.582868  13.231439   12.994221  -0.64445  \n",
       "261              0.585410  13.731212   11.457777  -0.64430  \n",
       "0                0.965248   5.501545    0.324280  -0.64370  \n",
       "10               0.965248   5.501545    0.324280  -0.64370  \n",
       "282              0.865046   9.340881   14.972215  -0.64360  \n",
       "255              0.461517  14.462334    0.403054  -0.64355  \n",
       "211              0.950813  13.174125    4.189244  -0.64350  \n",
       "67               1.000000  15.000000    0.000000  -0.64335  \n",
       "252              0.966017  13.130732   12.597376  -0.64325  \n",
       "149              0.406996  13.357600   12.587838  -0.64300  \n",
       "125              0.973763  13.966937    0.394683  -0.64290  \n",
       "200              0.444594   0.334067    0.248236  -0.64280  \n",
       "283              0.622532  13.967866   14.858967  -0.64275  \n",
       "190              0.928386   5.548046    0.741954  -0.64260  \n",
       "43               1.000000   0.000000    0.000000  -0.64230  \n",
       "189              0.834541  13.642555    6.452153  -0.64230  \n",
       "158              0.976091   1.731702   13.896799  -0.64230  \n",
       "180              0.399424  14.697309   14.267572  -0.64230  \n",
       "147              0.992814   8.909305    9.403998  -0.64220  \n",
       "164              0.937871  13.650221   12.299975  -0.64210  \n",
       "176              0.970334   3.219327   14.346987  -0.64210  \n",
       "202              0.923383  12.893570    1.712523  -0.64205  \n",
       "285              0.593668  11.800530   12.621982  -0.64200  \n",
       "260              0.673556  14.704642    5.176146  -0.64195  \n",
       "212              0.982363  14.296963   14.103147  -0.64190  \n",
       "87               0.907606  13.606182    0.777670  -0.64185  \n",
       "91               0.539095   7.873562    9.436934  -0.64185  \n",
       "113              0.841257   8.524519   13.551454  -0.64175  \n",
       "219              0.955435   0.617934   12.667184  -0.64175  \n",
       "242              0.363602  12.590141   11.774385  -0.64175  \n",
       "206              0.823604   0.839974    7.446417  -0.64170  \n",
       "101              0.303231   6.538552    9.283926  -0.64170  \n",
       "295              0.846953   3.891410   14.758651  -0.64155  \n",
       "121              0.999828  14.819613    5.590046  -0.64150  \n",
       "188              0.830616  11.728140    8.522373  -0.64150  \n",
       "119              0.478189  10.538324    1.723968  -0.64145  \n",
       "129              0.928958  12.326271   12.820286  -0.64135  \n",
       "247              0.991926  14.616288   14.718388  -0.64120  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_iter.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the resulting table as csv\n",
    "loc_iter.to_csv('Pickled_XGB_Skopt_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T23:20:46.355094Z",
     "start_time": "2019-11-28T23:20:44.324533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "#hist pour les continu\n",
    "plt.subplot(2,4,1)\n",
    "loc_iter.max_depth.plot(kind='hist')\n",
    "plt.legend()\n",
    "#plt.xticks(np.arange(0,1.1,0.1))\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "loc_iter.learning_rate.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "loc_iter.n_estimators.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "loc_iter.gamma.plot(kind='hist')\n",
    "#plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "loc_iter.subsample.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "loc_iter.colsample_bytree.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "loc_iter.reg_alpha.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,4,8)\n",
    "loc_iter.reg_lambda.plot(kind='hist')\n",
    "plt.legend()\n",
    "\n",
    "#hist pour les continu\n",
    "#plt.subplot(2,4,4)\n",
    "#loc_iter.min_samples_split.plot(kind='hist')\n",
    "#plt.legend()\n",
    "\n",
    "#plt.figure(figsize=(15,10))\n",
    "#plt.subplot(2,4,5)\n",
    "#loc_iter.min_samples_leaf.plot(kind='hist')\n",
    "#plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "#bar pour les discret\n",
    "#plt.subplot(2,4,7)\n",
    "#loc_iter.min_impurity_decrease.plot(kind='hist')\n",
    "#plt.xticks(rotation=0)\n",
    "#plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :\n",
    "Final parameters were already obtained at the time this is being written. Re-running with nb_calls = 11 to save time while cleaning up the code, but the initial optimal parameters were obtained with running the bayesian-optimization with nb_calls= 350 four times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T15:56:46.768044Z",
     "start_time": "2020-01-08T15:56:46.592616Z"
    }
   },
   "outputs": [],
   "source": [
    "xgg = XGBClassifier(learning_rate=0.02097570461116089,\n",
    "                               gamma=0.0012850274242561758,\n",
    "                               n_estimators=3779,\n",
    "                               max_depth=3,\n",
    "                               subsample=0.7143115552529244,\n",
    "                               colsample_bytree=0.9652482625436429,\n",
    "                               reg_alpha=5.501545045646806,\n",
    "                               reg_lambda=0.32428041642913136,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=42,\n",
    "                   booster = 'gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:13.312658Z",
     "start_time": "2020-01-08T15:57:22.134485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9652482625436429,\n",
       "              gamma=0.0012850274242561758, learning_rate=0.02097570461116089,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "              n_estimators=3779, n_jobs=-1, nthread=None,\n",
       "              objective='binary:logistic', random_state=42,\n",
       "              reg_alpha=5.501545045646806, reg_lambda=0.32428041642913136,\n",
       "              scale_pos_weight=1, seed=None, silent=None,\n",
       "              subsample=0.7143115552529244, verbosity=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:34.796120Z",
     "start_time": "2020-01-08T16:02:34.236728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6502"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat X_train and X_val pour predire X_test. Same for the y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:49.976711Z",
     "start_time": "2020-01-08T16:02:49.764944Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val = pd.concat([X_train,X_val], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:51.860449Z",
     "start_time": "2020-01-08T16:02:51.688522Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_val = pd.concat([y_train,y_val], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:52.709795Z",
     "start_time": "2020-01-08T16:02:52.545611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 313)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:02:55.726230Z",
     "start_time": "2020-01-08T16:02:55.562054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:22:55.852915Z",
     "start_time": "2020-01-08T16:15:12.915675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9652482625436429,\n",
       "              gamma=0.0012850274242561758, learning_rate=0.02097570461116089,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "              n_estimators=3779, n_jobs=-1, nthread=None,\n",
       "              objective='binary:logistic', random_state=42,\n",
       "              reg_alpha=5.501545045646806, reg_lambda=0.32428041642913136,\n",
       "              scale_pos_weight=1, seed=None, silent=None,\n",
       "              subsample=0.7143115552529244, verbosity=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgg.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:26:02.399820Z",
     "start_time": "2020-01-08T16:26:01.304741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6513"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test sur le 20% final de donnees mis de cotes, apres avoir combine x_train et x_validation\n",
    "xgg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the variables of the Data Frame in the same order between train and test to avoid errors on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:48:42.631217Z",
     "start_time": "2020-01-08T16:48:42.420864Z"
    }
   },
   "outputs": [],
   "source": [
    "#mettre les noms des colonnes du X originales dans une variable\n",
    "list_train = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:48:50.014190Z",
     "start_time": "2020-01-08T16:48:49.747741Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df_final[list_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:48:54.050655Z",
     "start_time": "2020-01-08T16:48:52.030476Z"
    }
   },
   "outputs": [],
   "source": [
    "#applique les prediction sur le nouveau DataFrame avec colonnes dans le meme ordre\n",
    "y_pred = xgg.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:48:56.254601Z",
     "start_time": "2020-01-08T16:48:56.085634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put y_pred in a DataFrame and Concatenate with ClientID (submission for this project needed to include only the predicted value for 'churn' and the associated ClientID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:49:14.785126Z",
     "start_time": "2020-01-08T16:49:14.607751Z"
    }
   },
   "outputs": [],
   "source": [
    "#mettre les preds en dataframe pour qu'ils aient le bon format\n",
    "y_pred_df1 = pd.DataFrame(y_pred)\n",
    "\n",
    "#concat dataframe des preds et la variable clientid opur la remise\n",
    "y_pred_final = pd.concat([df_final.clientid,y_pred_df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T16:49:15.662061Z",
     "start_time": "2020-01-08T16:49:15.487210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50005.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50006.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50007.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50008.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50009.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50011.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50012.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50013.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50014.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50015.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50016.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50017.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50018.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50020.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50022.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50023.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50025.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50026.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50027.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50028.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50029.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50030.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50032.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>50033.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50034.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>50035.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50036.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>50037.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>50038.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50039.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50040.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50041.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50042.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>50043.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50044.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>50045.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>50046.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>50047.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50048.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50049.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50050.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientid    0\n",
       "0    50001.0  1.0\n",
       "1    50002.0  1.0\n",
       "2    50003.0  1.0\n",
       "3    50004.0  0.0\n",
       "4    50005.0  1.0\n",
       "5    50006.0  0.0\n",
       "6    50007.0  0.0\n",
       "7    50008.0  0.0\n",
       "8    50009.0  0.0\n",
       "9    50010.0  0.0\n",
       "10   50011.0  0.0\n",
       "11   50012.0  0.0\n",
       "12   50013.0  1.0\n",
       "13   50014.0  1.0\n",
       "14   50015.0  1.0\n",
       "15   50016.0  0.0\n",
       "16   50017.0  1.0\n",
       "17   50018.0  1.0\n",
       "18   50019.0  1.0\n",
       "19   50020.0  1.0\n",
       "20   50021.0  1.0\n",
       "21   50022.0  1.0\n",
       "22   50023.0  0.0\n",
       "23   50024.0  0.0\n",
       "24   50025.0  1.0\n",
       "25   50026.0  1.0\n",
       "26   50027.0  0.0\n",
       "27   50028.0  0.0\n",
       "28   50029.0  1.0\n",
       "29   50030.0  1.0\n",
       "30   50031.0  1.0\n",
       "31   50032.0  1.0\n",
       "32   50033.0  1.0\n",
       "33   50034.0  1.0\n",
       "34   50035.0  0.0\n",
       "35   50036.0  0.0\n",
       "36   50037.0  1.0\n",
       "37   50038.0  0.0\n",
       "38   50039.0  0.0\n",
       "39   50040.0  0.0\n",
       "40   50041.0  0.0\n",
       "41   50042.0  1.0\n",
       "42   50043.0  0.0\n",
       "43   50044.0  0.0\n",
       "44   50045.0  1.0\n",
       "45   50046.0  0.0\n",
       "46   50047.0  1.0\n",
       "47   50048.0  0.0\n",
       "48   50049.0  0.0\n",
       "49   50050.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#verifier que tout marche\n",
    "display(y_pred_final.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T22:00:03.959154Z",
     "start_time": "2019-11-28T22:00:03.951139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loc_iter_xgb_opt']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump(loc_iter,'loc_iter_xgb_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T21:25:34.988075Z",
     "start_time": "2019-11-28T21:25:34.581343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_opt_search_result']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump(search_result,'xgb_opt_search_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to keep an eye out for :\n",
    "Values of gamma above 0.009\n",
    "Number of stumps (max_depth = 1)\n",
    "reg_lambda > 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
